{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6edf4c-79b8-4169-9faf-87e2c7d9e393",
   "metadata": {},
   "source": [
    "## Transformer experiment (based on Bukhsh, Saeed & Dijkman, 2021) \n",
    "\n",
    "Adapted from the original code by: \n",
    "\n",
    "- Zaharah A. Bukhsh, Aaqib Saeed, & Remco M. Dijkman. (2021). \"ProcessTransformer: Predictive Business Process Monitoring with Transformer Network\". arXiv preprint arXiv:2104.00721 \n",
    "\n",
    "github link: https://github.com/Zaharah/processtransformer\n",
    "\n",
    "This notebook contains the code that tests the Transformer model explained by Bukhsh et al. in their paper on the data provided by the Catharina hospital\n",
    "\n",
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfac90db-fa3e-42d9-93ef-b39e1822539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import sys\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from glob import glob\n",
    "pd.options.mode.chained_assignment = None  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#hyperas imports for hyperparameter optimization\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "#tensorflow imports for building neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, Accuracy, MeanSquaredError, MeanAbsoluteError\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.optimizers\n",
    "from tensorflow.keras import layers\n",
    "from transformer_lib import constants\n",
    "from transformer_lib.data import loader\n",
    "from transformer_lib.models import transformer\n",
    "from transformer_lib.models.transformer import TokenAndPositionEmbedding\n",
    "from transformer_lib.models.transformer import TransformerBlock\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "#sklearn imports for preprocessing, measuring performance and cross validation\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import feature_selection\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from other_lib import globalvar\n",
    "from other_lib.auk_score import AUK\n",
    "from other_lib.general_functions import prepare_dataset_for_model, find_all_csv_locations, image_encoder_cv, image_encoder_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5af932-d9bb-408c-b39e-3ebefc77ecfe",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "code use to build the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c7859f-cc9e-4396-b804-664393994da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calculates the embeddings for each activity for each trace\n",
    "#def create_model(x_train, x_test, y_train, y_test, binary):\n",
    "def create_model(x_train, x_val, x_test, y_train, y_val, y_test, binary, model_name):\n",
    "    \n",
    "    #include dict for embedding in tokenized datasets\n",
    "    x_dict= {\"[PAD]\": 0, \"[UNK]\": 1, \"arrive_cathlab\": 2, \"start_operation\": 3, \"end_operation\": 4, \"leave_cathlab\": 5, \"prepare\": 6, \n",
    "             \"start_introduction\": 7, \"end_introduction\": 8, \"cancellation\": 9, \"scheduled\": 10, \"waitfor_schedule\": 11, \"admission\": 12, \n",
    "             \"discharge\": 13, \"recovery\": 14, \"restart_noac\": 15, \"start_ac\": 16, \"stop_ac\": 17, \"paracetamol\": 18, \"measurebps\": 19, \n",
    "             \"measuretemps\": 20, \"test_hemoglobine\": 21, \"test_egfr\": 22, \"test_inr\": 23, \"test_trombocyten\": 24}\n",
    "    additional_features = ['MedicationCode_B01AA04', 'MedicationCode_B01AA07', 'MedicationCode_B01AE07', 'MedicationCode_B01AF01', \n",
    "                           'MedicationCode_B01AF02', 'MedicationCode_B01AF03', 'MedicationCode_N02AJ13', 'MedicationCode_N02BE01',\n",
    "                           'PlannedDuration', 'Duration', 'MedicationType', 'NOAC', 'MedicationStatus', 'temperature', \n",
    "                           'bloodPressure', 'Test_Hemoglobine', 'Test_eGFR', 'Test_INR', 'Test_Trombocyten']\n",
    "    vocab_size = len(x_dict) #number of different values, in this case 24 tokens\n",
    "    max_case_length = x_train.shape[1] #Used for token embedding, make this all columns except traceID\n",
    "    num_heads = {{choice([2, 3, 4])}} # number of attention heads in the transformer block\n",
    "    ff_dim = 64 #feedforward dimension, number of nodes for the dense layer\n",
    "    embed_dim = 36 #embedding dimension size\n",
    "    \n",
    "    x_train_list = [x_train]\n",
    "    x_val_list = [x_val]\n",
    "    x_test_list = [x_test]\n",
    "    \n",
    "    if 'tokenized' in model_name and 'additional' in model_name:\n",
    "        x_token_train = np.expand_dims(x_train[x_train.columns.difference(additional_features)], -1)\n",
    "        x_additional_train = x_train[additional_features]\n",
    "        x_token_val = np.expand_dims(x_val[x_val.columns.difference(additional_features)], -1)\n",
    "        x_additional_val = x_val[additional_features]\n",
    "        x_token_test = np.expand_dims(x_test[x_test.columns.difference(additional_features)], -1)\n",
    "        x_additional_test = x_test[additional_features]\n",
    "        \n",
    "        x_train_list = [x_token_train, x_additional_train]\n",
    "        x_val_list = [x_token_val, x_additional_val]\n",
    "        x_test_list = [x_token_test, x_additional_test]\n",
    "        \n",
    "    #for tokenized encodings an additional pass through the TokenAndPositionEmbedding layer is required\n",
    "    if 'tokenized' in model_name:\n",
    "        if 'additional' in model_name: #if dataset = tokenized + additional, the additional data needs to be split and concatenated later\n",
    "            \n",
    "            tokenized_input = layers.Input(shape=(x_token_train.shape[1],)) #input layer for tokenized data\n",
    "            additional_input = layers.Input(shape=(x_additional_train.shape[1],)) #input layer for additional data\n",
    "            inputs = [tokenized_input, additional_input]\n",
    "            \n",
    "            x = TokenAndPositionEmbedding(x_token_train.shape[1], vocab_size, embed_dim)(tokenized_input)\n",
    "            x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "            x = layers.GlobalAveragePooling1D()(x)\n",
    "            x = layers.Concatenate(axis=1)([x, additional_input])\n",
    "        else:\n",
    "            inputs = layers.Input(shape=(max_case_length,))\n",
    "            x = TokenAndPositionEmbedding(max_case_length, vocab_size, embed_dim)(inputs)\n",
    "            x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "            x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    else:\n",
    "        embed_dim = max_case_length\n",
    "        inputs = layers.Input(shape=(max_case_length, 1)) #add a ',1' to account for additional dimension\n",
    "        x = TransformerBlock(embed_dim, num_heads, ff_dim)(inputs)\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    #x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout({{uniform(0, 0.3)}})(x)\n",
    "    x = layers.Dense({{choice([64, 128, 256])}}, activation=\"relu\")(x)\n",
    "    x = layers.Dropout({{uniform(0, 0.3)}})(x)\n",
    "\n",
    "    optimizer = tensorflow.keras.optimizers.Adam(learning_rate={{choice([10 ** -4, 10 ** -3, 10 ** -2])}}, clipnorm=1.)   \n",
    "    \n",
    "    #determine output shape based on prediction task, either for binary/length of stay prediction\n",
    "    if binary:\n",
    "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "                      metrics=['accuracy', globalvar.f1, globalvar.precision, globalvar.recall, globalvar.auc])\n",
    "    else:\n",
    "        outputs = layers.Dense(1, activation=\"linear\")(x)\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse', 'mape'])\n",
    "    \n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=10, verbose=0, mode='min')\n",
    "    callbacks_list = [earlystop]\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.fit(x_train_list, y_train, epochs={{choice([50, 100])}}, \n",
    "              validation_data=(x_val_list, y_val), callbacks=callbacks_list, \n",
    "              batch_size={{choice([128, 256])}}, verbose=0, shuffle=True)\n",
    "    \n",
    "    score = model.evaluate(x_test_list, y_test, verbose=0)\n",
    "\n",
    "    if binary:\n",
    "        f1 = score[2]\n",
    "        return {'loss': -f1, 'status': STATUS_OK, 'model': model} #take the negative of f1 here since objective is to minimize and f1 usually maens higher is better\n",
    "    else:\n",
    "        mae = score[1]\n",
    "        return {'loss': mae, 'status': STATUS_OK, 'model': model} #dont take negative value here since you want to minimize the mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74880af2-c372-4f43-a879-d28bbb69a158",
   "metadata": {},
   "source": [
    "## With best model, calculate cv scores\n",
    "Function below is used to crossvalidate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf9d03a-91c6-4e2c-bda1-bfd41a2bc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_best_model(X, y, best_model, best_run, binary, output_dir, model_name, model_type):\n",
    "    if binary: \n",
    "        kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) #cannot do stratifiedkfold for regression tasks\n",
    "        cv_accuracy_scores = []\n",
    "        cv_f1_scores = []\n",
    "        cv_precision_scores = []\n",
    "        cv_recall_scores = []\n",
    "        cv_auc_scores = []\n",
    "        cv_auk_scores = []\n",
    "    else:\n",
    "        kfold = KFold(n_splits=4, shuffle=True, random_state=42) #regular kfold here\n",
    "        cv_mae_scores = []\n",
    "        cv_mse_scores = []\n",
    "        cv_mape_scores = []\n",
    "\n",
    "    callbacks_list = [globalvar.earlystop]\n",
    "    fold_counter = 1\n",
    "\n",
    "    for train, test in kfold.split(X, y): #cross validation to obtain stable results, only have to do padded_X since padded_X1 has same \n",
    "        print('Now starting fold: {} for model: {}'.format(fold_counter, model_name))\n",
    "        \n",
    "        x_train = X.loc[train]\n",
    "        x_test = X.loc[test]\n",
    "        y_train = y.loc[train]\n",
    "        y_test = y.loc[test]\n",
    "\n",
    "        #fill NaN value with mean of training data for both train and test data. Cant do mean per group since many groups have no data at all\n",
    "        x_train.fillna(x_train.mean(), inplace=True)\n",
    "        x_test.fillna(x_train.mean(), inplace=True)\n",
    "\n",
    "        #scaling for non-additional features, only on train/test data to prevent data leakage, complete X returned without scaling\n",
    "        additional_features = ['MedicationCode_B01AA04', 'MedicationCode_B01AA07', 'MedicationCode_B01AE07', 'MedicationCode_B01AF01', \n",
    "                               'MedicationCode_B01AF02', 'MedicationCode_B01AF03', 'MedicationCode_N02AJ13', 'MedicationCode_N02BE01',\n",
    "                               'PlannedDuration', 'Duration', 'MedicationType', 'NOAC', 'MedicationStatus', 'temperature', \n",
    "                               'bloodPressure', 'Test_Hemoglobine', 'Test_eGFR', 'Test_INR', 'Test_Trombocyten']\n",
    "\n",
    "        scaler = StandardScaler()    \n",
    "\n",
    "        if 'tokenized' in model_name and 'transformer' not in model_type: #means all columns need to be encoded, regardless of additional or not\n",
    "            x_train = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "            x_test = pd.DataFrame(scaler.fit_transform(x_test))\n",
    "        elif 'additional' in model_name.lower() and 'ae_agg' not in model_name.lower(): #means only the additionally added columns need to be scaled\n",
    "            x_train[additional_features] = scaler.fit_transform(x_train[additional_features])\n",
    "            x_test[additional_features] = scaler.fit_transform(x_test[additional_features])\n",
    "\n",
    "        #For lstm models, the input needs to be 3d instead of 2d. Therefore, add another dimension to the data\n",
    "        if model_type == 'lstm' or model_type=='transformer' and 'additional' not in model_name.lower():\n",
    "            x_train = np.expand_dims(x_train, -1)\n",
    "            x_test= np.expand_dims(x_test, -1) \n",
    "        \n",
    "        x_train_list = [x_train]\n",
    "        x_test_list = [x_test]\n",
    "        \n",
    "        if 'tokenized' in model_name and 'additional' in model_name:\n",
    "            x_token_train = np.expand_dims(x_train[x_train.columns.difference(additional_features)], -1)\n",
    "            x_additional_train = x_train[additional_features]\n",
    "            x_token_test = np.expand_dims(x_test[x_test.columns.difference(additional_features)], -1)\n",
    "            x_additional_test = x_test[additional_features]\n",
    "\n",
    "            x_train_list = [x_token_train, x_additional_train]\n",
    "            x_test_list = [x_token_test, x_additional_test]\n",
    "            \n",
    "            \n",
    "        best_model.fit(x_train_list, #use the same [train] indexes for both padded_X and padded_X1 to get correct values\n",
    "                       y_train, \n",
    "                       epochs=best_run['epochs'], \n",
    "                       callbacks=callbacks_list, \n",
    "                       batch_size=best_run['batch_size'],\n",
    "                       verbose=0)\n",
    "\n",
    "        scores = best_model.evaluate(x_test_list, y_test, verbose=0)\n",
    "\n",
    "        if binary:\n",
    "            y_pred = best_model.predict(x_test_list, verbose=0)\n",
    "            scores.append(AUK(y_test, y_pred.flatten()).calculate_auk()) #add AUK scores\n",
    "            \n",
    "            print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1] * 100)) #accuracy of the test prediction\n",
    "            cv_accuracy_scores.append(scores[1])\n",
    "            cv_f1_scores.append(scores[2])\n",
    "            cv_precision_scores.append(scores[3])\n",
    "            cv_recall_scores.append(scores[4])\n",
    "            cv_auc_scores.append(scores[5])\n",
    "            cv_auk_scores.append(scores[6])\n",
    "        else:\n",
    "            print('{} score: {}'.format(best_model.metrics_names[1], scores[1]))\n",
    "            cv_mae_scores.append(scores[1])\n",
    "            cv_mse_scores.append(scores[2])\n",
    "            cv_mape_scores.append(scores[3])\n",
    "\n",
    "        fold_counter += 1 #update fold counter\n",
    "\n",
    "    #calculate measures\n",
    "    if binary:\n",
    "        print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cv_accuracy_scores)*100, numpy.std(cv_accuracy_scores)*100))\n",
    "        measures = [numpy.mean(cv_accuracy_scores), \n",
    "                    numpy.std(cv_accuracy_scores),\n",
    "                    numpy.mean(cv_f1_scores), \n",
    "                    numpy.std(cv_f1_scores),\n",
    "                    numpy.mean(cv_precision_scores),\n",
    "                    numpy.std(cv_precision_scores),\n",
    "                    numpy.mean(cv_recall_scores), \n",
    "                    numpy.std(cv_recall_scores),\n",
    "                    numpy.mean(cv_auc_scores), \n",
    "                    numpy.std(cv_auc_scores),\n",
    "                    numpy.mean(cv_auk_scores),\n",
    "                    numpy.std(cv_auk_scores)] #average over all splits\n",
    "    else:\n",
    "        print('average mae score over all splits: {} (+/- {}%)'.format(numpy.mean(cv_mae_scores), numpy.std(cv_mae_scores)))\n",
    "        measures = [numpy.mean(cv_mae_scores),\n",
    "                    numpy.std(cv_mae_scores),\n",
    "                    numpy.mean(cv_mse_scores),\n",
    "                    numpy.std(cv_mse_scores),\n",
    "                    numpy.mean(cv_mape_scores),\n",
    "                    numpy.std(cv_mape_scores)]\n",
    "\n",
    "    #save and write results + model\n",
    "    if binary:\n",
    "        numpy.savetxt(output_dir + 'results\\\\' + model_name + '-' + str(numpy.mean(cv_accuracy_scores).round(2)) + '.csv', numpy.atleast_2d(measures),\n",
    "                      delimiter=',', fmt='%6f', header=\"acc, acc_std, f1, f1_std, precision, precision_std, recall, recall_std, auc, auc_std, auk, auk_std\") #write the model scores to a csv file\n",
    "\n",
    "        if model_type == 'transformer':\n",
    "            best_model.save_weights(output_dir + 'models\\\\' + model_name + '_model-weights.h5', save_format='h5') #transformer models can only save weights, not complete models\n",
    "        else:\n",
    "            best_model.save(output_dir + 'models\\\\' + model_name + '.h5')\n",
    "\n",
    "        text_file = open(output_dir + 'results\\\\hyperparameters\\\\' + model_name + \"-\" + str(numpy.mean(cv_accuracy_scores).round(2)) + \".txt\", \"w\") #write hyperparameters of best run\n",
    "        text_file.write(str(best_run))\n",
    "        text_file.close()\n",
    "    else:\n",
    "        numpy.savetxt(output_dir + 'results\\\\' + model_name + '-' + str(numpy.mean(cv_mae_scores).round(2)) + '.csv', numpy.atleast_2d(measures),\n",
    "                      delimiter=',', fmt='%6f', header='mae, mae_std, mse, mse_std, mape, mape_std') #write the model scores to a csv file\n",
    "\n",
    "        if model_type == 'transformer':\n",
    "            best_model.save_weights(output_dir + 'models\\\\' + model_name + '_model-weights.h5', save_format='h5') #transformer models can only save weights, not complete models\n",
    "        else:\n",
    "            best_model.save(output_dir + 'models\\\\' + model_name + '.h5')\n",
    "\n",
    "        text_file = open(output_dir + 'results\\\\hyperparameters\\\\' + model_name + '-' + str(numpy.mean(cv_mae_scores).round(2)) + '.txt', 'w') #write hyperparameters of best run\n",
    "        text_file.write(str(best_run))\n",
    "        text_file.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6fa936-5d88-4bde-b225-2588cd49104e",
   "metadata": {},
   "source": [
    "## Loop for all combinations\n",
    "function below combines all functions into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6ca57d-1fc6-4eb9-bf0d-cf0dfcba23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buthsch_et_al(file_location, output_dir):\n",
    "    model_name = file_location.split(\"\\\\\")[-1:][0].split('.')[0] #get filename (without.csv)\n",
    "    print('Now starting with dataset: {}'.format(model_name))\n",
    "\n",
    "    #preprocess and split training/test data\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test, binary, X, y, model_type = prepare_dataset_for_model(file_location, model_type='transformer')\n",
    "    \n",
    "    #optimize the model hyperparameters through hyperas \n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                  data=prepare_dataset_for_model,\n",
    "                                  algo=tpe.suggest,\n",
    "                                  max_evals=5, #number of \"random\" parameter configurations that are tested\n",
    "                                  trials=Trials(),\n",
    "                                  data_args=(file_location, model_type), #supply the arguments for the prepare_dataset_for_model function here\n",
    "                                  eval_space=True,\n",
    "                                  notebook_name='(Buthsch et al. - Transformer)',\n",
    "                                  verbose=False)\n",
    "    \n",
    "    #need to convert x_test into list first, in the case of tokenized_additional encoding which requires multiple inputs in the model\n",
    "    x_test_list = [x_test]\n",
    "    if 'tokenized' in model_name and 'additional' in model_name:\n",
    "        additional_features = ['MedicationCode_B01AA04', 'MedicationCode_B01AA07', 'MedicationCode_B01AE07', 'MedicationCode_B01AF01', \n",
    "                               'MedicationCode_B01AF02', 'MedicationCode_B01AF03', 'MedicationCode_N02AJ13', 'MedicationCode_N02BE01',\n",
    "                               'PlannedDuration', 'Duration', 'MedicationType', 'NOAC', 'MedicationStatus', 'temperature', \n",
    "                               'bloodPressure', 'Test_Hemoglobine', 'Test_eGFR', 'Test_INR', 'Test_Trombocyten']\n",
    "        x_token_test = np.expand_dims(x_test[x_test.columns.difference(additional_features)], -1)\n",
    "        x_additional_test = x_test[additional_features]\n",
    "        x_test_list = [x_token_test, x_additional_test]\n",
    "    \n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    best_scores = best_model.evaluate(x_test_list, y_test, verbose=0)\n",
    "    print(best_scores)\n",
    "    print(best_model.metrics_names)\n",
    "\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)\n",
    "    \n",
    "    #add AUK & Kappa scores and save the best performing optimized model\n",
    "    if binary:\n",
    "        y_pred = best_model.predict(x_test_list, verbose=0)\n",
    "        best_scores.append(AUK(y_test, y_pred.flatten()).calculate_auk())\n",
    "        best_scores.append(AUK(y_test, y_pred.flatten()).kappa_curve())\n",
    "        pd.DataFrame(best_scores).transpose().to_csv(output_dir + 'opt_results\\\\' + model_name + '.csv')\n",
    "    else:\n",
    "        pd.DataFrame(best_scores).transpose().to_csv(output_dir + 'opt_results\\\\' + model_name + '.csv')\n",
    "    \n",
    "    #cross validate to obtain reliable performance of best performing model\n",
    "    cross_validate_best_model(X=X, y=y, best_model=best_model, best_run=best_run, binary=binary, output_dir=output_dir, model_name=model_name, model_type=model_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab950e3-3ade-494d-88da-035e78607e74",
   "metadata": {},
   "source": [
    "Finally, generate the results using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3d3060-3ed5-4166-8069-a795020a32e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 csv files left\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\model_results\\\\transformer\\\\'\n",
    "file_locations = find_all_csv_locations('transformer')\n",
    "\n",
    "for file_location in file_locations:\n",
    "    buthsch_et_al(file_location, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
