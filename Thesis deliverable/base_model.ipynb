{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399a387d-92b7-49d8-a216-4f2d692a2cb4",
   "metadata": {},
   "source": [
    "# Simple base model for all 3 prediction targets\n",
    "\n",
    "In this notebook, a simple base model is created for all 3 prediction targets: cancellation, paracetamol and length of stay.\n",
    "\n",
    "For the binary prediction targets, the model has to at least outperform a random model that is aware of the class distribution for it to be considered useful, AKA a random rate classifier (weighted guessing). For length of stay, a simple logistic regression model is created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dc9a4f3-f2a5-4831-93c8-052cc7227d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from other_lib import globalvar\n",
    "from other_lib.general_functions import find_all_csv_locations\n",
    "from other_lib.auk_score import AUK\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, r2_score, make_scorer\n",
    "\n",
    "from matplotlib import pyplot\n",
    "pd.options.mode.chained_assignment = None  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#function to load and prepare data\n",
    "def prepare_dataset_for_model(file_location, model_type):\n",
    "    \n",
    "    df = pd.read_csv(file_location)\n",
    "    model_name = file_location.split(\"\\\\\")[-1:][0].split('.')[0] #get filename (without.csv)\n",
    "    binary = False if 'los' in model_name.lower() else True #check if a binary prediction (for paracetamol/cancel datasets) or a regression prediction (for length of stay) is being made\n",
    "    \n",
    "    #define label (aka outcome) and prediction data\n",
    "    y = df['Label'] if 'Label' in df else df['outcome']\n",
    "    X = df.loc[:, df.columns != 'Label'] if 'Label' in df else df.loc[:, df.columns != 'outcome']\n",
    "    \n",
    "    #remove TraceID (aka case_id) from the training and testing data\n",
    "    if 'TraceID' in X.columns or 'case_id' in X.columns:\n",
    "        X = X.drop('TraceID', 1) if 'TraceID' in X.columns else X.drop('case_id', 1)\n",
    "    \n",
    "    #train/val/test set split, must be done before scaling and upsampling to prevent data leakage between train/test data\n",
    "    if binary:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "        \n",
    "    #fill NaN value with mean of training data for both train and test data. Cant do mean per group since many groups have no data at all\n",
    "    x_train.fillna(x_train.mean(), inplace=True)\n",
    "    x_test.fillna(x_train.mean(), inplace=True)\n",
    "    X.fillna(x_train.mean(), inplace=True)\n",
    "    \n",
    "    #scaling for non-additional features, only on train/test data to prevent data leakage, complete X returned without scaling\n",
    "    additional_features = ['MedicationCode_B01AA04', 'MedicationCode_B01AA07', 'MedicationCode_B01AE07', 'MedicationCode_B01AF01', \n",
    "                           'MedicationCode_B01AF02', 'MedicationCode_B01AF03', 'MedicationCode_N02AJ13', 'MedicationCode_N02BE01',\n",
    "                           'PlannedDuration', 'Duration', 'MedicationType', 'NOAC', 'MedicationStatus', 'temperature', \n",
    "                           'bloodPressure', 'Test_Hemoglobine', 'Test_eGFR', 'Test_INR', 'Test_Trombocyten']\n",
    "\n",
    "    scaler = StandardScaler()    \n",
    "    \n",
    "    if 'tokenized' in model_name and 'transformer' not in model_type: #means all columns need to be encoded, regardless of additional or not\n",
    "        x_train = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "        x_test = pd.DataFrame(scaler.fit_transform(x_test))\n",
    "    elif 'additional' in model_name.lower() and 'ae_agg' not in model_name.lower(): #means only the additionally added columns need to be scaled\n",
    "        x_train[additional_features] = scaler.fit_transform(x_train[additional_features])\n",
    "        x_test[additional_features] = scaler.fit_transform(x_test[additional_features])\n",
    "        \n",
    "    #oversampling of training data for cancellation data, skip test data (data leakage) and validation (validation needs to be representative of test data)\n",
    "    if 'can' in model_name:\n",
    "        oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "        x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "        \n",
    "    #For lstm models, the input needs to be 3d instead of 2d. Therefore, add another dimension to the data so the data passes correctly\n",
    "    if model_type == 'lstm' or model_type=='transformer' and 'additional' not in model_name.lower():\n",
    "        x_train = np.expand_dims(x_train, -1)\n",
    "        x_test= np.expand_dims(x_test, -1) \n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, binary, X, y, model_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f3822-ccd0-4475-9c7e-d684e997da50",
   "metadata": {},
   "source": [
    "## Randomly weighted baseline\n",
    "\n",
    "For the two binary prediction targets, the performance of a randomly weighted classifier is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbaa825-cb92-47a3-adfc-9a4c7f0259e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true/false values for paracetamol:  {1.0: 700, 0.0: 528}\n",
      "Number of true/false values for cancellation:  {0.0: 994, 1.0: 234}\n"
     ]
    }
   ],
   "source": [
    "#use any of the encoded datasets since the labels are all the same regardless of encoding strategy\n",
    "df_par = pd.read_csv('C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_par.csv')\n",
    "df_can = pd.read_csv('C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_can.csv')\n",
    "\n",
    "print('Number of true/false values for paracetamol: ', df_par['Label'].value_counts().to_dict())\n",
    "print('Number of true/false values for cancellation: ', df_can['Label'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b69f6af-358d-4a3e-a8b2-fac0915f0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy for paracetamol dataset:  0.5098\n",
      "Baseline accuracy for cancellation dataset:  0.6915\n"
     ]
    }
   ],
   "source": [
    "def random_rate_classifier(true_vals):\n",
    "    \n",
    "    total_predictions = len(true_vals)\n",
    "    positive_chance = (true_vals.values == 1).sum() / total_predictions\n",
    "    negative_chance = (true_vals.values == 0).sum() / total_predictions\n",
    "    \n",
    "    baseline_accuracy = round(positive_chance**2 + negative_chance**2, 4)\n",
    "    baseline_predictions = np.random.choice([0, 1], size=(total_predictions,), p=[negative_chance, positive_chance])\n",
    "    \n",
    "    return baseline_accuracy\n",
    "    \n",
    "baseline_acc_par = random_rate_classifier(df_par['Label'])\n",
    "baseline_acc_can = random_rate_classifier(df_can['Label'])\n",
    "\n",
    "print('Baseline accuracy for paracetamol dataset: ', baseline_acc_par)\n",
    "print('Baseline accuracy for cancellation dataset: ', baseline_acc_can)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac4315-1f11-4391-81ca-47094823084c",
   "metadata": {},
   "source": [
    "Furthermore, I've also created a very simple baseline logistic regression model that can be used to compare with the complexer neural networks.\n",
    "\n",
    "## Logistic regression baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4342e4e9-3070-448a-8f51-7a1f22ec10bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file location:  C:\\Users\\20190337\\Downloads\\Tracebook_v2 (Projectfolder)\\encoded_logs\\one_hot_encoded_logs\\one_hot_can_additional.csv\n",
      "x_train shape:  (1590, 41) | x_test shape:  (246, 41) | X shape:  (1228, 41)\n",
      "y_train shape:  (1590,) | y_test shape:  (246,) | y shape:  (1228,)\n"
     ]
    }
   ],
   "source": [
    "file_location = 'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_can_additional.csv'\n",
    "model_name = file_location.split(\"\\\\\")[-1:][0].split('.')[0] #get filename (without.csv)\n",
    "\n",
    "x_train, x_test, y_train, y_test, binary, X, y, model_type = prepare_dataset_for_model(file_location, model_type='logistic')\n",
    "\n",
    "print('x_train shape: ', x_train.shape, '| x_test shape: ', x_test.shape, '| X shape: ', X.shape)\n",
    "print('y_train shape: ', y_train.shape, '| y_test shape: ', y_test.shape, '| y shape: ', y.shape)\n",
    "\n",
    "def calc_auk_score(y_true, y_pred):\n",
    "    return(AUK(y_true, y_pred).calculate_auk())\n",
    "\n",
    "auk_scorer = make_scorer(calc_auk_score, greater_is_better=True)\n",
    "\n",
    "log_regression = LogisticRegression()\n",
    "log_regression.fit(x_train, y_train)\n",
    "y_pred = log_regression.predict(x_test)\n",
    "y_pred\n",
    "\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'f1': 'f1',\n",
    "           'precision':'precision',\n",
    "           'recall': 'recall',\n",
    "           'auc': 'roc_auc',\n",
    "           'auk': auk_scorer}\n",
    "\n",
    "scores = cross_validate(log_regression, X, y, scoring=scoring, cv=5, return_train_score=False, error_score=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a134fa-d5a7-4d56-9f73-704e56eeb00f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#custom scorer function that calculates AUK\n",
    "def calc_auk_score(y_true, y_pred):\n",
    "    return(AUK(y_true, y_pred).calculate_auk())\n",
    "\n",
    "auk_scorer = make_scorer(calc_auk_score, greater_is_better=True)\n",
    "\n",
    "def logistic_regression(x_train, x_test, y_train, y_test, X, y):\n",
    "\n",
    "    log_regression = LogisticRegression()\n",
    "    log_regression.fit(x_train, y_train)\n",
    "    y_pred = log_regression.predict(x_test)\n",
    "\n",
    "    importance = log_regression.coef_[0]\n",
    "    \n",
    "    scoring = {'acc': 'accuracy',\n",
    "               'f1': 'f1',\n",
    "               'precision':'precision',\n",
    "               'recall': 'recall',\n",
    "               'auc': 'roc_auc',\n",
    "               'auk': auk_scorer\n",
    "               }\n",
    "    \n",
    "    scores = cross_validate(log_regression, X, y, scoring=scoring, cv=5, return_train_score=False)\n",
    "    \n",
    "    #print(scores)\n",
    "    \n",
    "    scores.pop('fit_time')\n",
    "    scores.pop('score_time')\n",
    "    scores['# acc'] = scores.pop('test_acc')\n",
    "    scores[' f1'] = scores.pop('test_f1')\n",
    "    scores[' precision'] = scores.pop('test_precision')\n",
    "    scores[' recall'] = scores.pop('test_recall')\n",
    "    scores[' auc'] = scores.pop('test_auc')\n",
    "    scores[' auk'] = scores.pop('test_auk')\n",
    "\n",
    "    mean_scores = {key:sum(scores[key])/len(scores[key]) for key in scores}\n",
    "\n",
    "    return mean_scores\n",
    "\n",
    "#simple function to output mean cv scores to csv file\n",
    "def save_cv_results(mean_scores, output_dir, model_name):\n",
    "    df = pd.DataFrame(mean_scores, index=[0])\n",
    "    np.savetxt(output_dir + model_name + '.csv', np.atleast_2d(df),\n",
    "                      delimiter=',', fmt='%6f', header='acc, f1, precision, recall, auc, auk')\n",
    "    \n",
    "output_dir = 'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\model_results\\\\baseline\\\\'\n",
    "file_locations = ['C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_can.csv',\n",
    "                  'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_can_additional.csv',\n",
    "                  'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_par.csv',\n",
    "                  'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_par_additional.csv']\n",
    "\n",
    "#loop through the 4 files, calculate performance of the logistic regression model and save scores\n",
    "for file_location in file_locations:\n",
    "    model_name = file_location.split(\"\\\\\")[-1:][0].split('.')[0] #get filename (without.csv)\n",
    "    print('Now calculating cv scores for: ', model_name)\n",
    "    x_train, x_test, y_train, y_test, binary, X, y, model_type = prepare_dataset_for_model(file_location, model_type='logistic') #train/test split\n",
    "    scores = logistic_regression(x_train, x_test, y_train, y_test, X, y) #calc cv scores\n",
    "\n",
    "    print(scores)\n",
    "    \n",
    "    save_cv_results(scores, output_dir, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd83481-4cd2-4a54-9372-3c4754926286",
   "metadata": {},
   "source": [
    "## Linear regression baseline model\n",
    "\n",
    "For the LOS baseline model, a simple linear regression model is used. Again, start with preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ded1cdfc-b345-498d-bc40-f8e31430f06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file location:  C:\\Users\\20190337\\Downloads\\Tracebook_v2 (Projectfolder)\\encoded_logs\\one_hot_encoded_logs\\one_hot_los.csv\n",
      "x_train shape:  (933, 23) | x_test shape:  (234, 23) | X shape:  (1167, 23)\n",
      "y_train shape:  (933,) | y_test shape:  (234,) | y shape:  (1167,)\n"
     ]
    }
   ],
   "source": [
    "file_location = 'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_los.csv'\n",
    "model_name = file_location.split(\"\\\\\")[-1:][0].split('.')[0] #get filename (without.csv)\n",
    "\n",
    "print('file location: ', file_location)\n",
    "\n",
    "x_train, x_test, y_train, y_test, binary, X, y, model_type = prepare_dataset_for_model(file_location, model_type='linear')\n",
    "\n",
    "print('x_train shape: ', x_train.shape, '| x_test shape: ', x_test.shape, '| X shape: ', X.shape)\n",
    "print('y_train shape: ', y_train.shape, '| y_test shape: ', y_test.shape, '| y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ddec69a-1043-486f-874f-eb269de9c61b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now calculated cv scores for:  one_hot_los\n",
      "{'# mae': 267.5477487002304, ' mape': 0.2887656443021881, ' mse': 116210.07829962033}\n",
      "Now calculated cv scores for:  one_hot_los_additional\n",
      "{'# mae': 261.60554400109027, ' mape': 0.2796983705723021, ' mse': 108992.89140402494}\n"
     ]
    }
   ],
   "source": [
    "#Function that calculates the linear regression performance\n",
    "def linear_regression(x_train, x_test, y_train, y_test, X, y):\n",
    "    \n",
    "    lin_regression = LinearRegression()\n",
    "    lin_regression.fit(x_train, y_train)\n",
    "    y_pred = lin_regression.predict(x_test)\n",
    "\n",
    "    importance = lin_regression.coef_\n",
    "    \n",
    "    scoring = {'mae': 'neg_mean_absolute_error',\n",
    "               'mape':'neg_mean_absolute_percentage_error',\n",
    "               'mse': 'neg_mean_squared_error',}\n",
    "    \n",
    "    #cross validate and clean up scores\n",
    "    scores = cross_validate(lin_regression, X, y, scoring=scoring, cv=5, return_train_score=False)\n",
    "    scores.pop('fit_time')\n",
    "    scores.pop('score_time')\n",
    "    scores['# mae'] = scores.pop('test_mae')\n",
    "    scores[' mape'] = scores.pop('test_mape')\n",
    "    scores[' mse'] = scores.pop('test_mse')\n",
    "    \n",
    "    mean_scores = {key:sum(-scores[key])/len(scores[key]) for key in scores}\n",
    "    \n",
    "    return mean_scores\n",
    "\n",
    "#simple function to output mean cv scores to csv file\n",
    "def save_cv_results(mean_scores, output_dir, model_name):\n",
    "    df = pd.DataFrame(scores, index=[0])\n",
    "    np.savetxt(output_dir + model_name + '.csv', np.atleast_2d(df),\n",
    "                      delimiter=',', fmt='%6f', header='mae, mape, mse')\n",
    "\n",
    "#calculate the performance\n",
    "output_dir = 'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\model_results\\\\baseline\\\\'\n",
    "file_locations = ['C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_los.csv',\n",
    "                  'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\encoded_logs\\\\one_hot_encoded_logs\\\\one_hot_los_additional.csv']\n",
    "\n",
    "for file_location in file_locations:\n",
    "    model_name = file_location.split(\"\\\\\")[-1:][0].split('.')[0] #get filename (without.csv)\n",
    "    print('Now calculated cv scores for: ', model_name)\n",
    "\n",
    "    x_train, x_test, y_train, y_test, binary, X, y, model_type = prepare_dataset_for_model(file_location, model_type='linear') #train/test split\n",
    "    scores = linear_regression(x_train, x_test, y_train, y_test, X, y) #calc cv scores\n",
    "    print(scores)\n",
    "    save_cv_results(scores, output_dir, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
