{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6edf4c-79b8-4169-9faf-87e2c7d9e393",
   "metadata": {},
   "source": [
    "## Inception CNN (based on Di Mauro et al, 2019)\n",
    "\n",
    "Adapted from the original code by: \n",
    "\n",
    "- Di Mauro, N., Appice, A., & Basile, T. M. A. (2019). Activity Prediction of Business Process Instances with Inception CNN Models. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 11946 LNAI(November), 348â€“361. https://doi.org/10.1007/978-3-030-35166-3_25 \n",
    "\n",
    "github link: https://github.com/TaXxER/rnnalpha\n",
    "\n",
    "This notebook contains the code that tests an Inception CNN model originally created by Di Mauro et al. on the data provided by the Catharina hospital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2012e88b-8cc1-4024-87ea-e3f1468518e6",
   "metadata": {},
   "source": [
    "## General imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3d9407-113e-4d87-85b6-d2fafb0c8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import sys\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from glob import glob\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#hyperas imports for hyperparameter optimization\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "#tensorflow imports for building neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Concatenate, Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Reshape, MaxPooling1D, Flatten, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical, custom_object_scope\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, Accuracy, MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.optimizers\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "#sklearn imports for preprocessing, measuring performance and cross validation\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn import feature_selection\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from other_lib import globalvar\n",
    "from other_lib.auk_score import AUK\n",
    "from other_lib.general_functions import prepare_dataset_for_model, find_all_csv_locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f71a91-680b-49ae-8b51-1c3daa467a1f",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "code use to build the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb980749-1e23-434d-bb88-45a8d83e4d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function that calculates the embeddings for each activity for each trace\n",
    "def create_model(x_train, x_val, x_test, y_train, y_val, y_test, binary):\n",
    "    \n",
    "    #create input layer\n",
    "    inputs = [] #create empty list to store the input layers in, will be updated and used when compiling the model\n",
    "    input_layer = Input(shape=(x_train.shape[1], 1)) #input layer, width of data = timesteps with each timestep having 1 feature (1 value per column)\n",
    "    inputs = [input_layer]\n",
    "    \n",
    "    #add first inception module\n",
    "    filters = []\n",
    "    for i in range({{choice([3, 4])}}): #number of different conv modules in the inception layer\n",
    "        filters.append(Conv1D(filters=32, strides=1, kernel_size=1+i, activation='relu', padding='same')(input_layer)) #add the conv layers of different sizes\n",
    "    filters.append(MaxPooling1D(pool_size=3, strides=1, padding='same')(input_layer)) #add the max pool layer\n",
    "    concat_layer = Concatenate(axis=2)(filters) #concatenate the output of the different conv modules and max pool layer to get output of inception module\n",
    "    \n",
    "    for m in range({{choice([0,1,2])}}): #number of inception modules you want to stack on top of the first one (for a total of either 1, 2 or 3)\n",
    "        filters = []\n",
    "        for i in range({{choice([3, 4])}}): #number of different conv modules in the inception layer\n",
    "            filters.append(Conv1D(filters=32, strides=1, kernel_size=1+i, activation='relu', padding='same')(concat_layer)) #add the conv layers of different sizes\n",
    "        filters.append(MaxPooling1D(pool_size=3, strides=1, padding='same')(concat_layer)) #add the max pool layer\n",
    "        concat_layer = Concatenate(axis=2)(filters) #concatenate the output of the different conv modules and max pool layer to get output of inception module\n",
    "\n",
    "    pool = GlobalMaxPooling1D()(concat_layer)\n",
    "    \n",
    "    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\n",
    "    if choiceval == 'adam':\n",
    "        optim = tensorflow.keras.optimizers.Adam(learning_rate={{choice([10 ** -4, 10 ** -3, 10 ** -2])}}, clipnorm=1.)\n",
    "    elif choiceval == 'rmsprop':\n",
    "        optim = rmsprop = tensorflow.keras.optimizers.RMSprop(learning_rate={{choice([10 ** -4, 10 ** -3, 10 ** -2])}}, clipnorm=1.)\n",
    "    else:\n",
    "        optim = tensorflow.keras.optimizers.SGD(learning_rate={{choice([10 ** -4, 10 ** -3, 10 ** -2])}}, clipnorm=1.)\n",
    "    \n",
    "    #determine output shape based on prediction task, either for binary/length of stay prediction\n",
    "    if binary:\n",
    "        output_layer = Dense(1, activation='sigmoid')(pool)\n",
    "        model = Model(inputs=inputs, outputs=output_layer)\n",
    "        model.compile(optimizer=optim, loss='binary_crossentropy',\n",
    "                      metrics=['accuracy', globalvar.f1, globalvar.precision, globalvar.recall, globalvar.auc])\n",
    "        print('Created binary model!')\n",
    "    else:\n",
    "        output_layer = Dense(1, activation='linear')(pool)\n",
    "        model = Model(inputs=inputs, outputs=output_layer)\n",
    "        model.compile(optimizer=optim, loss='mae', metrics=['mae', 'mse', 'mape'])\n",
    "    \n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=15, verbose=0, mode='min')\n",
    "    callbacks_list = [earlystop]\n",
    "    \n",
    "    model.summary()\n",
    "    model.fit(x_train, y_train, epochs={{choice([50, 100])}}, \n",
    "              validation_data=(x_val, y_val), callbacks=callbacks_list, \n",
    "              batch_size={{choice([2**7, 2**8])}}, verbose=0)\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print('score evaluated: ', score)\n",
    "    print('binary: ', binary)\n",
    "    \n",
    "    if binary:\n",
    "        f1 = score[2]\n",
    "        return {'loss': -f1, 'status': STATUS_OK, 'model': model} #take the negative of f1 here since objective is to minimize and f1 usually means higher is better\n",
    "    else:\n",
    "        mae = score[1]\n",
    "        return {'loss': mae, 'status': STATUS_OK, 'model': model} #dont take negative value here since you want to minimize the mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb31da6-46d3-4cd5-bd28-c3f08e4d8b9b",
   "metadata": {},
   "source": [
    "## With best model, calculate cv scores\n",
    "function below is used to crossvalidate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2866381-5c41-4c4a-8180-5c3e2e3b8e69",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate_best_model(X, y, best_model, best_run, binary, output_dir, model_name, model_type):\n",
    "    if binary: \n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) #cannot do stratifiedkfold for regression tasks\n",
    "        cv_accuracy_scores = []\n",
    "        cv_f1_scores = []\n",
    "        cv_precision_scores = []\n",
    "        cv_recall_scores = []\n",
    "        cv_auc_scores = []\n",
    "        cv_auk_scores = []\n",
    "    else:\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42) #regular kfold here\n",
    "        cv_mae_scores = []\n",
    "        cv_mse_scores = []\n",
    "        cv_mape_scores = []\n",
    "\n",
    "    callbacks_list = [globalvar.earlystop]\n",
    "    fold_counter = 1\n",
    "\n",
    "    for train, test in kfold.split(X, y): #cross validation to obtain stable results, only have to do padded_X since padded_X1 has same \n",
    "        print('Now starting fold: {} for model: {}'.format(fold_counter, model_name))\n",
    "        \n",
    "        x_train = X.loc[train]\n",
    "        x_test = X.loc[test]\n",
    "        y_train = y.loc[train]\n",
    "        y_test = y.loc[test]\n",
    "\n",
    "        #fill NaN value with mean of training data for both train and test data. Cant do mean per group since many groups have no data at all\n",
    "        x_train.fillna(x_train.mean(), inplace=True)\n",
    "        x_test.fillna(x_train.mean(), inplace=True)\n",
    "\n",
    "        #scaling for non-additional features, only on train/test data to prevent data leakage, complete X returned without scaling\n",
    "        additional_features = ['MedicationCode_B01AA04', 'MedicationCode_B01AA07', 'MedicationCode_B01AE07', 'MedicationCode_B01AF01', \n",
    "                               'MedicationCode_B01AF02', 'MedicationCode_B01AF03', 'MedicationCode_N02AJ13', 'MedicationCode_N02BE01',\n",
    "                               'PlannedDuration', 'Duration', 'MedicationType', 'NOAC', 'MedicationStatus', 'temperature', \n",
    "                               'bloodPressure', 'Test_Hemoglobine', 'Test_eGFR', 'Test_INR', 'Test_Trombocyten']\n",
    "\n",
    "        scaler = StandardScaler()    \n",
    "\n",
    "        if 'tokenized' in model_name and 'transformer' not in model_type: #means all columns need to be encoded, regardless of additional or not\n",
    "            x_train = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "            x_test = pd.DataFrame(scaler.fit_transform(x_test))\n",
    "        elif 'additional' in model_name.lower() and 'ae_agg' not in model_name.lower(): #means only the additionally added columns need to be scaled\n",
    "            x_train[additional_features] = scaler.fit_transform(x_train[additional_features])\n",
    "            x_test[additional_features] = scaler.fit_transform(x_test[additional_features])\n",
    "\n",
    "        #For lstm models, the input needs to be 3d instead of 2d. Therefore, add another dimension to the data\n",
    "        if model_type == 'lstm' or model_type=='transformer':\n",
    "            x_train = np.expand_dims(x_train, -1)\n",
    "            x_test= np.expand_dims(x_test, -1)\n",
    "            \n",
    "        #oversample train data for cancellation datasets\n",
    "        if 'can' in model_name:\n",
    "            oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "            x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "            \n",
    "            \n",
    "        best_model.fit(x_train, #use the same [train] indexes for both padded_X and padded_X1 to get correct values\n",
    "                       y_train, \n",
    "                       epochs=best_run['epochs'], \n",
    "                       callbacks=callbacks_list, \n",
    "                       batch_size=best_run['batch_size'],\n",
    "                       verbose=0)\n",
    "\n",
    "        scores = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "        if binary:\n",
    "            y_pred = best_model.predict(x_test, verbose=0)\n",
    "            scores.append(AUK(y_test, y_pred.flatten()).calculate_auk()) #add AUK scores\n",
    "            \n",
    "            print(\"%s: %.2f%%\" % (best_model.metrics_names[1], scores[1] * 100)) #accuracy of the test prediction\n",
    "            cv_accuracy_scores.append(scores[1])\n",
    "            cv_f1_scores.append(scores[2])\n",
    "            cv_precision_scores.append(scores[3])\n",
    "            cv_recall_scores.append(scores[4])\n",
    "            cv_auc_scores.append(scores[5])\n",
    "            cv_auk_scores.append(scores[6])\n",
    "        else:\n",
    "            print('{} score: {}'.format(best_model.metrics_names[1], scores[1]))\n",
    "            cv_mae_scores.append(scores[1])\n",
    "            cv_mse_scores.append(scores[2])\n",
    "            cv_mape_scores.append(scores[3])\n",
    "\n",
    "        fold_counter += 1 #update fold counter\n",
    "\n",
    "    #calculate measures\n",
    "    if binary:\n",
    "        print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cv_accuracy_scores)*100, numpy.std(cv_accuracy_scores)*100))\n",
    "        measures = [numpy.mean(cv_accuracy_scores), \n",
    "                    numpy.std(cv_accuracy_scores),\n",
    "                    numpy.mean(cv_f1_scores), \n",
    "                    numpy.std(cv_f1_scores),\n",
    "                    numpy.mean(cv_precision_scores),\n",
    "                    numpy.std(cv_precision_scores),\n",
    "                    numpy.mean(cv_recall_scores), \n",
    "                    numpy.std(cv_recall_scores),\n",
    "                    numpy.mean(cv_auc_scores), \n",
    "                    numpy.std(cv_auc_scores),\n",
    "                    numpy.mean(cv_auk_scores),\n",
    "                    numpy.std(cv_auk_scores)] #average over all splits\n",
    "    else:\n",
    "        print('average mae score over all splits: {} (+/- {}%)'.format(numpy.mean(cv_mae_scores), numpy.std(cv_mae_scores)))\n",
    "        measures = [numpy.mean(cv_mae_scores),\n",
    "                    numpy.std(cv_mae_scores),\n",
    "                    numpy.mean(cv_mse_scores),\n",
    "                    numpy.std(cv_mse_scores),\n",
    "                    numpy.mean(cv_mape_scores),\n",
    "                    numpy.std(cv_mape_scores)]\n",
    "\n",
    "    #save and write results + model\n",
    "    if binary:\n",
    "        numpy.savetxt(output_dir + 'results\\\\' + model_name + '-' + str(numpy.mean(cv_accuracy_scores).round(2)) + '.csv', numpy.atleast_2d(measures),\n",
    "                      delimiter=',', fmt='%6f', header=\"acc, acc_std, f1, f1_std, precision, precision_std, recall, recall_std, auc, auc_std, auk, auk_std\") #write the model scores to a csv file\n",
    "\n",
    "        if model_type == 'transformer':\n",
    "            best_model.save_weights(output_dir + 'models\\\\' + model_name + '_model-weights.h5', save_format='h5') #transformer models can only save weights, not complete models\n",
    "        else:\n",
    "            best_model.save(output_dir + 'models\\\\' + model_name + '.h5')\n",
    "\n",
    "        text_file = open(output_dir + 'results\\\\hyperparameters\\\\' + model_name + \"-\" + str(numpy.mean(cv_accuracy_scores).round(2)) + \".txt\", \"w\") #write hyperparameters of best run\n",
    "        text_file.write(str(best_run))\n",
    "        text_file.close()\n",
    "    else:\n",
    "        numpy.savetxt(output_dir + 'results\\\\' + model_name + '-' + str(numpy.mean(cv_mae_scores).round(2)) + '.csv', numpy.atleast_2d(measures),\n",
    "                      delimiter=',', fmt='%6f', header='mae, mae_std, mse, mse_std, mape, mape_std') #write the model scores to a csv file\n",
    "\n",
    "        if model_type == 'transformer':\n",
    "            best_model.save_weights(output_dir + 'models\\\\' + model_name + '_model-weights.h5', save_format='h5') #transformer models can only save weights, not complete models\n",
    "        else:\n",
    "            best_model.save(output_dir + 'models\\\\' + model_name + '.h5')\n",
    "\n",
    "        text_file = open(output_dir + 'results\\\\hyperparameters\\\\' + model_name + '-' + str(numpy.mean(cv_mae_scores).round(2)) + '.txt', 'w') #write hyperparameters of best run\n",
    "        text_file.write(str(best_run))\n",
    "        text_file.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb10eee-135f-4dd9-8211-78a53b578c77",
   "metadata": {},
   "source": [
    "## Loop for all combinations\n",
    "function below combines all functions into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9f39545-a9c7-497a-8c25-4c90dbea23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def di_mauro_et_al(file_location, output_dir):\n",
    "    model_name = file_location.split(\"\\\\\")[-1:][0].split('.')[0] #get filename (without.csv)\n",
    "    print('Now starting with dataset: {}'.format(model_name))\n",
    "\n",
    "    #preprocess and split training/test data\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test, binary, X, y, model_type = prepare_dataset_for_model(file_location, model_type='cnn')\n",
    "    \n",
    "    #optimize the model hyperparameters through hyperas \n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                  data=prepare_dataset_for_model,\n",
    "                                  algo=tpe.suggest,\n",
    "                                  max_evals=5, #number of \"random\" parameter configurations that are tested\n",
    "                                  trials=Trials(),\n",
    "                                  data_args=(file_location, model_type), #supply the arguments for the prepare_dataset_for_model function here\n",
    "                                  eval_space=True,\n",
    "                                  notebook_name='(Di Mauro et al. - CNN)',\n",
    "                                  verbose=False)\n",
    "    \n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    best_scores = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(best_scores)\n",
    "    print(best_model.metrics_names)\n",
    "\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)\n",
    "    \n",
    "    #add AUK & Kappa scores and save the best performing optimized model\n",
    "    if binary:\n",
    "        y_pred = best_model.predict(x_test, verbose=0)\n",
    "        best_scores.append(AUK(y_test, y_pred.flatten()).calculate_auk())\n",
    "        best_scores.append(AUK(y_test, y_pred.flatten()).kappa_curve())\n",
    "        pd.DataFrame(best_scores).transpose().to_csv(output_dir + 'opt_results\\\\' + model_name + '.csv')\n",
    "    else:\n",
    "        pd.DataFrame(best_scores).transpose().to_csv(output_dir + 'opt_results\\\\' + model_name + '.csv')\n",
    "\n",
    "    \n",
    "    #cross validate to obtain reliable performance of best performing model\n",
    "    cross_validate_best_model(X=X, y=y, best_model=best_model, best_run=best_run, binary=binary, output_dir=output_dir, model_name=model_name, model_type=model_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce4e0d1-9c4d-4a02-93ef-9968fe693afc",
   "metadata": {},
   "source": [
    "Finally, generate the results using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c090346-b2f0-4aac-a64b-29f6d3f5daa9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 csv files left\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'C:\\\\Users\\\\20190337\\\\Downloads\\\\Tracebook_v2 (Projectfolder)\\\\model_results\\\\di_mauro_cnn\\\\'\n",
    "file_locations = find_all_csv_locations('di_mauro_cnn')\n",
    "\n",
    "for file_location in file_locations:\n",
    "    di_mauro_et_al(file_location, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
